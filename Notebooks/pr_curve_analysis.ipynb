{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PR Curve Analysis for CNN Model\n",
        "\n",
        "This notebook:\n",
        "1. Loads the CNN model from August 2025\n",
        "2. Computes the Precision-Recall curve\n",
        "3. Exports the data for TikZ plotting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "import pickle\n",
        "import os\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import pandas as pd\n",
        "sys.path.append(os.path.abspath(\"..\"))\n",
        "from utils.project_classes import CNNClassifier\n",
        "import utils.project_functions as pf\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define paths\n",
        "MODEL_PATH = \"../Models/cnn_2025-08-12.pth\"\n",
        "OUTPUT_PATH = \"../Predictions/pr_curve_data.dat\"\n",
        "\n",
        "# Data parameters for testing\n",
        "U = [40, 100]  # Different U values to test\n",
        "L = [96]       # System size\n",
        "exp = [\"A\"]    # Experiment type\n",
        "frames = range(1, 11)  # Use first 10 frames for testing\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_104955/1275497228.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(MODEL_PATH))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully!\n",
            "Model architecture:\n",
            "CNNClassifier(\n",
            "  (conv1): Conv2d(5, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=1568, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=3, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Initialize and load model using the CNNClassifier from project_classes.py\n",
        "model = CNNClassifier()\n",
        "model.load_state_dict(torch.load(MODEL_PATH))\n",
        "model.to(device)\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "print(f\"Model architecture:\\n{model}\")\n",
        "\n",
        "# Create test dataset from VTK files\n",
        "all_tensors = []\n",
        "all_labels = []\n",
        "\n",
        "print(\"\\nProcessing VTK files to create test dataset...\")\n",
        "for u in U:\n",
        "    for l in L:\n",
        "        for e in exp:\n",
        "            previous_defects = np.array([]).reshape(0,2)\n",
        "            for frame in frames:\n",
        "                try:\n",
        "                    file_path = f\"../Data/MAI_U{str(u).zfill(3)}_L_{str(l).zfill(3)}_{e}/mpcd_{frame}.vtk\"\n",
        "                    _eigen_vals, _eigen_vecs = pf.load_and_pad_vtk(file_path, pad_width=4)\n",
        "                    frame_defects = pf.find_defects(_eigen_vals, _eigen_vecs, 0.3)\n",
        "                    _defects = np.concatenate([previous_defects, frame_defects])\n",
        "                    \n",
        "                    # Get labeled data\n",
        "                    samples = pf.predict_field(model, _eigen_vals, _eigen_vecs, _defects, device=device, filename=f\"w\")\n",
        "                    \n",
        "                    # Extract tensors and labels\n",
        "                    for sample in samples:\n",
        "                        if sample.label is not None:  # Only use samples with ground truth labels\n",
        "                            all_tensors.append(sample.tensor)\n",
        "                            all_labels.append(sample.label)\n",
        "                    \n",
        "                    previous_defects = frame_defects\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {file_path}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "# Convert lists to tensors\n",
        "X_test = torch.stack([torch.tensor(t, dtype=torch.float32) for t in all_tensors]).to(device)\n",
        "y_test = torch.tensor(all_labels, dtype=torch.long).to(device)\n",
        "\n",
        "print(f\"\\nTest dataset created with {len(all_tensors)} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'test_data'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m test_data \u001b[38;5;241m=\u001b[39m \u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m X_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      4\u001b[0m y_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'test_data'"
          ]
        }
      ],
      "source": [
        "# Get model predictions\n",
        "with torch.no_grad():\n",
        "    y_pred = torch.softmax(model(X_test), dim=1)\n",
        "    \n",
        "# Convert predictions to numpy for sklearn\n",
        "y_pred_np = y_pred.cpu().numpy()\n",
        "y_test_np = y_test.cpu().numpy()\n",
        "\n",
        "# Compute PR curve for each class\n",
        "n_classes = y_pred_np.shape[1]\n",
        "precision = {}\n",
        "recall = {}\n",
        "average_precision = {}\n",
        "\n",
        "print(\"\\nComputing PR curves for each class...\")\n",
        "for i in range(n_classes):\n",
        "    precision[i], recall[i], _ = precision_recall_curve(\n",
        "        (y_test_np == i).astype(int),\n",
        "        y_pred_np[:, i]\n",
        "    )\n",
        "    average_precision[i] = average_precision_score(\n",
        "        (y_test_np == i).astype(int),\n",
        "        y_pred_np[:, i]\n",
        "    )\n",
        "\n",
        "print(\"\\nAverage Precision Scores:\")\n",
        "for i in range(n_classes):\n",
        "    print(f\"Class {i}: {average_precision[i]:.3f}\")\n",
        "\n",
        "# Print class distribution in test set\n",
        "print(\"\\nClass distribution in test set:\")\n",
        "unique, counts = np.unique(y_test_np, return_counts=True)\n",
        "for class_idx, count in zip(unique, counts):\n",
        "    print(f\"Class {class_idx}: {count} samples ({count/len(y_test_np)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export PR curve data for TikZ\n",
        "def export_pr_data(precision_dict, recall_dict, output_path):\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    \n",
        "    with open(output_path, 'w') as f:\n",
        "        # Write header\n",
        "        f.write(\"% Precision-Recall curve data for TikZ plotting\\n\")\n",
        "        f.write(\"% Format: Class Recall Precision\\n\\n\")\n",
        "        \n",
        "        # Write data for each class\n",
        "        for class_idx in precision_dict.keys():\n",
        "            # Combine precision and recall into pairs\n",
        "            for p, r in zip(precision_dict[class_idx], recall_dict[class_idx]):\n",
        "                f.write(f\"{class_idx} {r:.6f} {p:.6f}\\n\")\n",
        "            # Add a blank line between classes for easier reading\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "# Export the data\n",
        "export_pr_data(precision, recall, OUTPUT_PATH)\n",
        "print(f\"PR curve data exported to: {OUTPUT_PATH}\")\n",
        "\n",
        "# Preview the first few lines of the exported file\n",
        "with open(OUTPUT_PATH, 'r') as f:\n",
        "    print(\"\\nPreview of exported data:\")\n",
        "    print(\"\".join(f.readlines()[:10]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using the Data with TikZ\n",
        "\n",
        "The exported data file contains the PR curve points in the following format:\n",
        "```\n",
        "Class Recall Precision\n",
        "```\n",
        "\n",
        "Example TikZ code to plot the curves:\n",
        "```latex\n",
        "\\begin{tikzpicture}\n",
        "    \\begin{axis}[\n",
        "        xlabel=Recall,\n",
        "        ylabel=Precision,\n",
        "        grid=major,\n",
        "        xmin=0, xmax=1,\n",
        "        ymin=0, ymax=1,\n",
        "    ]\n",
        "    \n",
        "    % Plot data for each class\n",
        "    \\addplot[blue] table[x index=1, y index=2] {pr_curve_data.dat};\n",
        "    \\addlegendentry{Class 0}\n",
        "    \n",
        "    % Add more \\addplot commands for other classes\n",
        "    \n",
        "    \\end{axis}\n",
        "\\end{tikzpicture}\n",
        "```\n",
        "\n",
        "Note: You may need to filter the data for each class separately when plotting, or use a tool like `awk` to split the data file by class.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
